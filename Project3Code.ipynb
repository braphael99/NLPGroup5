{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48346131-57ae-4d2b-9f6e-df6e9e046e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (2.17.1)\n",
      "Requirement already satisfied: transformers in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (0.20.2)\n",
      "Requirement already satisfied: packaging in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680a9703-47c6-47d4-97e2-6b3c5c0d6787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "#At least 4.11.0 required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f23c87b-9273-43d0-a756-a55e615a9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up model\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981651e-ff6d-4d98-9519-4eb0cf2e0bd2",
   "metadata": {},
   "source": [
    "We must now load the dataset from our local JSON files. \n",
    "\n",
    "For refernece, see https://huggingface.co/docs/datasets/en/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74b3a79-e6d1-4eda-903b-64123e120ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: The ranger and the rustler both were riding horses that galloped at the same speed.  The rustler left at 01:00 where as the ranger left at 0500 hours. Who has traveled further?? \n",
      "O1: the ranger\n",
      "O2: the rustler\n",
      "A: Option 2\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "#Load the dataset as train, validation, and test.\n",
    "#We use the dev data as validation.\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files={'train':'QQA Data/QQA_train.json', \n",
    "                                           'validation':'QQA Data/QQA_dev.json', \n",
    "                                           'test':'QQA Data/QQA_test.json'})\n",
    "\n",
    "#Printing the dataset contents\n",
    "print('Q: ' + dataset['train'][0]['question'])\n",
    "print('O1: ' + dataset['train'][0]['Option1'])\n",
    "print('O2: ' + dataset['train'][0]['Option2'])\n",
    "print('A: ' + dataset['train'][0]['answer'])\n",
    "\n",
    "#Load evaluation metric\n",
    "accuracy_metric = load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fcaace2-8030-4319-bc42-5ed145b06744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question_sci_10E', 'question', 'Option2', 'question_char', 'answer', 'Option1', 'question_mask', 'type', 'question_sci_10E_char'],\n",
       "        num_rows: 564\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question_sci_10E', 'question', 'Option2', 'question_char', 'answer', 'Option1', 'question_mask', 'type', 'question_sci_10E_char'],\n",
       "        num_rows: 81\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question_sci_10E', 'question', 'Option2', 'question_char', 'answer', 'Option1', 'question_mask', 'type', 'question_sci_10E_char'],\n",
       "        num_rows: 162\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa20a-caaf-4610-924e-676a7be967b6",
   "metadata": {},
   "source": [
    "The imported data is of the form:\n",
    "\n",
    "{\"question\": \"Jame's mother has a photo of Jane standing at a height of 14 inches, whereas a mountain appears to have height of 26 cm. It looks that way because? \", \"Option1\": \"the mountain was farther away\", \"Option2\": \"Jane was farther away\", \"answer\": \"Option 2\", \"type\": \"Type_3\", \"question_sci_10E\": \"Jame's mother has a photo of Jane standing at a height of 1.4000000000E+01 inches, whereas a mountain appears to have height of 2.6000000000E+01 cm. It looks that way because? \", \"question_char\": \"Jame's mother has a photo of Jane standing at a height of 1 4 inches, whereas a mountain appears to have height of 2 6 cm. It looks that way because? \", \"question_sci_10E_char\": \"Jame's mother has a photo of Jane standing at a height of 1 . 4 0 0 0 0 0 0 0 0 0 E + 0 1 inches, whereas a mountain appears to have height of 2 . 6 0 0 0 0 0 0 0 0 0 E + 0 1 cm. It looks that way because? \", \"question_mask\": \"Jame's mother has a photo of Jane standing at a height of [Num] inches, whereas a mountain appears to have height of [Num] cm. It looks that way because? \"\n",
    "\n",
    "For reference, see:\n",
    "https://huggingface.co/docs/transformers/en/tasks/multiple_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9435d4a-07ed-4765-9b9e-f164e90c573a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'Option2', 'answer', 'Option1'],\n",
       "        num_rows: 564\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'Option2', 'answer', 'Option1'],\n",
       "        num_rows: 81\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'Option2', 'answer', 'Option1'],\n",
       "        num_rows: 162\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get rid of the other columns\n",
    "datasets = datasets.remove_columns(['question_char', 'question_sci_10E',\n",
    "                         'question_sci_10E_char',\n",
    "                         'question_mask', 'type',])\n",
    "\n",
    "#We now only have a question, answer, and 2 options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5147-a707-4d31-8bd7-98a2f593ba82",
   "metadata": {},
   "source": [
    "For evaluation, see https://huggingface.co/spaces/evaluate-metric/accuracy\n",
    "\n",
    "For fine-tuning, see: https://huggingface.co/docs/transformers/en/training#train-with-pytorch-trainer\n",
    "\n",
    "For handing multiple choice, see https://huggingface.co/docs/transformers/en/tasks/multiple_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f364ab20-e1da-4ca8-a7d0-a3bbb6d5a949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'A race car and a pickup both drove on the highway at the same speed. The driver of the race car got tired and parked after 29 mins, while the driver of the pickup ran for 43 mins. Which vehicle ultimately went the greater distance?? ',\n",
       " 'Option2': 'pickup',\n",
       " 'answer': 'Option 2',\n",
       " 'Option1': 'race car'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e251187a-8ecc-4a47-9e5a-9ad0df35ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2426, 2149, 999, 102, 1996, 17727, 14122, 2953, 2003, 10514, 2015, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "tokenizer(\"AMONG US!\", \"The impostor is SUS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c27ec50f-ebe7-4826-acf7-f2f0e90bb0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "max_seq_length = tokenizer.model_max_length\n",
    "\n",
    "choice_list = [\"Option1\", \"Option2\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # replicating first sentences 4 times\n",
    "    first_sentences = []\n",
    "    for q in examples['question']:\n",
    "      for i in range(2):\n",
    "        first_sentences.append(q)\n",
    "\n",
    "    # putting all choices in a list\n",
    "    second_sentences = []\n",
    "    for choice in choice_list:\n",
    "        second_sentences.append(choice)\n",
    "\n",
    "\n",
    "    # Tokenize\n",
    "    print(first_sentences)\n",
    "    \n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True, max_length=max_seq_length)\n",
    "    # Un-flatten\n",
    "    dic = {'input_ids':[], 'token_type_ids':[], 'attention_mask':[]}\n",
    "\n",
    "    for k, v in tokenized_examples.items():\n",
    "        for i in range(0, len(v), 2):\n",
    "            dic[k].append(v[i:i+2])\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a6f8fda-78af-4194-8f2d-a7cf9c2854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"Option1\", \"Option2\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence two times to go with the two possibilities of second sentences.\n",
    "    first_sentences = [[context] * 2 for context in examples[\"question\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    question_headers = examples[\"question\"]\n",
    "    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n",
    "    \n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8b34511-0436-4d34-8a75-d70dbbc41ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [89, 90]\n"
     ]
    }
   ],
   "source": [
    "examples = datasets[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])\n",
    "\n",
    "#EVERYTHING UP TO HERE WORKS FOR REAL. EVERYTHING BEYOND IS... NOT SO GREAT. BE WARNED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcc528fc-e12f-4480-a433-8767d7a84ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        #labels = [int(feature.pop(label_name)) for feature in features]\n",
    "        labels = [1, 2]\n",
    "        #Error checking\n",
    "        print(labels)\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bad17457-782a-4fad-a724-93d447550687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model_name = 'deepset/roberta-base-squad2'\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "470da043-32eb-4ca3-b48b-19b26e06a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     13\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mDataCollatorForMultipleChoice(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer),\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/trainer.py:1821\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1821\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1822\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/accelerate/data_loader.py:452\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 25\u001b[0m, in \u001b[0;36mDataCollatorForMultipleChoice.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[1;32m     24\u001b[0m num_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     [{k: v[i] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_choices)] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(flattened_features, [])\n\u001b[1;32m     30\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     31\u001b[0m     flattened_features,\n\u001b[1;32m     32\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m )\n",
      "Cell \u001b[0;32mIn[52], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[1;32m     24\u001b[0m num_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     25\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 26\u001b[0m     [{k: v[i] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_choices)] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(flattened_features, [])\n\u001b[1;32m     30\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     31\u001b[0m     flattened_features,\n\u001b[1;32m     32\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m )\n",
      "Cell \u001b[0;32mIn[52], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[1;32m     24\u001b[0m num_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     25\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 26\u001b[0m     [{k: v[i] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_choices)] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(flattened_features, [])\n\u001b[1;32m     30\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     31\u001b[0m     flattened_features,\n\u001b[1;32m     32\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m )\n",
      "Cell \u001b[0;32mIn[52], line 26\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[1;32m     24\u001b[0m num_choices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     25\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 26\u001b[0m     [{k: \u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m feature\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_choices)] \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[1;32m     27\u001b[0m ]\n\u001b[1;32m     28\u001b[0m flattened_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(flattened_features, [])\n\u001b[1;32m     30\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     31\u001b[0m     flattened_features,\n\u001b[1;32m     32\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_train,\n",
    "    eval_dataset=encoded_validation,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fee49e-a81a-4794-8129-0273cc66267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    print(predictions)\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2924531-5976-47a4-9b4a-4137b9d2cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    #args=training_args,\n",
    "    train_dataset=encoded_train,\n",
    "    eval_dataset=encoded_validation,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e002f-632e-468b-8e17-ac79a209c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "trainer.save_model() # Saves the tokenizer too for easy upload\n",
    "\n",
    "metrics = train_result.metrics\n",
    "\n",
    "\n",
    "max_train_samples = (\n",
    "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "        )\n",
    "\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b786e93d-9c7d-4fb6-bacd-8e35dacd3a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d74de2-ca62-4c6d-94e1-4674d6ad7909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
