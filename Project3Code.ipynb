{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48346131-57ae-4d2b-9f6e-df6e9e046e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell if any import errors occur\n",
    "#! pip install datasets transformers\n",
    "#! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a2f13c-6b75-4175-959f-88a010dc60d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.36.2\n"
     ]
    }
   ],
   "source": [
    "#Collecting all imports\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "\n",
    "print(transformers.__version__)\n",
    "#Transformers should be at least 4.11.0 required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981651e-ff6d-4d98-9519-4eb0cf2e0bd2",
   "metadata": {},
   "source": [
    "We must now load the dataset from our local JSON files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74b3a79-e6d1-4eda-903b-64123e120ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c4ad6b4c9d49d5af4867113ee4c706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359ce568eb9c459287bff91314b849f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee2275d6ba147928434b3379985383f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: The ranger and the rustler both were riding horses that galloped at the same speed.  The rustler left at 01:00 where as the ranger left at 0500 hours. Who has traveled further?? \n",
      "O1: the ranger\n",
      "O2: the rustler\n",
      "A: Option 2\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset as train, validation, and test.\n",
    "#We use the dev data as validation.\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files={'train':'Project/QQA_Data/QQA_train.json', \n",
    "                                           'validation':'Project/QQA_Data/QQA_dev.json', \n",
    "                                           'test':'Project/QQA_Data/QQA_test.json'})\n",
    "\n",
    "#Printing the dataset contents\n",
    "print('Q: ' + datasets['train'][0]['question'])\n",
    "print('O1: ' + datasets['train'][0]['Option1'])\n",
    "print('O2: ' + datasets['train'][0]['Option2'])\n",
    "print('A: ' + datasets['train'][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fcaace2-8030-4319-bc42-5ed145b06744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question_mask', 'Option2', 'question_sci_10E_char', 'question_sci_10E', 'answer', 'question', 'question_char', 'Option1', 'type'],\n",
       "        num_rows: 564\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question_mask', 'Option2', 'question_sci_10E_char', 'question_sci_10E', 'answer', 'question', 'question_char', 'Option1', 'type'],\n",
       "        num_rows: 81\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question_mask', 'Option2', 'question_sci_10E_char', 'question_sci_10E', 'answer', 'question', 'question_char', 'Option1', 'type'],\n",
       "        num_rows: 162\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print dataset structure\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa20a-caaf-4610-924e-676a7be967b6",
   "metadata": {},
   "source": [
    "The imported data is of the form:\n",
    "\n",
    "{\"question\": \"Jame's mother has a photo of Jane standing at a height of 14 inches, whereas a mountain appears to have height of 26 cm. It looks that way because? \", \"Option1\": \"the mountain was farther away\", \"Option2\": \"Jane was farther away\", \"answer\": \"Option 2\", \"type\": \"Type_3\", \"question_sci_10E\": \"Jame's mother has a photo of Jane standing at a height of 1.4000000000E+01 inches, whereas a mountain appears to have height of 2.6000000000E+01 cm. It looks that way because? \", \"question_char\": \"Jame's mother has a photo of Jane standing at a height of 1 4 inches, whereas a mountain appears to have height of 2 6 cm. It looks that way because? \", \"question_sci_10E_char\": \"Jame's mother has a photo of Jane standing at a height of 1 . 4 0 0 0 0 0 0 0 0 0 E + 0 1 inches, whereas a mountain appears to have height of 2 . 6 0 0 0 0 0 0 0 0 0 E + 0 1 cm. It looks that way because? \", \"question_mask\": \"Jame's mother has a photo of Jane standing at a height of [Num] inches, whereas a mountain appears to have height of [Num] cm. It looks that way because? \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9435d4a-07ed-4765-9b9e-f164e90c573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get rid of the other columns\n",
    "datasets = datasets.remove_columns(['question_char', 'question_sci_10E',\n",
    "                         'question_sci_10E_char',\n",
    "                         'question_mask', 'type',])\n",
    "\n",
    "#We now only have a question, answer, and 2 options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bc7f584-de67-4956-b749-06e886d81b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming for compatibility later\n",
    "datasets = datasets.rename_column('answer', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f5147-a707-4d31-8bd7-98a2f593ba82",
   "metadata": {},
   "source": [
    "For evaluation, see https://huggingface.co/spaces/evaluate-metric/accuracy\n",
    "\n",
    "For fine-tuning, see: https://huggingface.co/docs/transformers/en/training#train-with-pytorch-trainer\n",
    "\n",
    "For handing multiple choice, see https://huggingface.co/docs/transformers/en/tasks/multiple_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a3e901-9c1c-4676-80d9-0f5f75404d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f4774472864bf4909ab62ffabc60cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b54b9bf71ad416688702badf164aee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eec87497df4616b414f9a78948ced6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set correct answer to an integer. \n",
    "\n",
    "def set_labels(example):\n",
    "    #print(example)\n",
    "    example[\"label\"] = int(example[\"label\"][-1]) - 1\n",
    "    return example\n",
    "\n",
    "datasets = datasets.map(set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f364ab20-e1da-4ca8-a7d0-a3bbb6d5a949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Option2': 'pickup',\n",
       " 'label': 1,\n",
       " 'question': 'A race car and a pickup both drove on the highway at the same speed. The driver of the race car got tired and parked after 29 mins, while the driver of the pickup ran for 43 mins. Which vehicle ultimately went the greater distance?? ',\n",
       " 'Option1': 'race car'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e251187a-8ecc-4a47-9e5a-9ad0df35ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 4049, 1012, 102, 2023, 2003, 1037, 4946, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n",
    "tokenizer(\"This is a boat.\", \"This is a plane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a6f8fda-78af-4194-8f2d-a7cf9c2854d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"Option1\", \"Option2\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Repeat each first sentence two times to go with the two possibilities of second sentences.\n",
    "    first_sentences = [[context] * 2 for context in examples[\"question\"]]\n",
    "    # Grab all second sentences possible for each context.\n",
    "    question_headers = examples[\"question\"]\n",
    "    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n",
    "    \n",
    "    # Flatten everything\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    # Un-flatten\n",
    "    return {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b34511-0436-4d34-8a75-d70dbbc41ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 [89, 90]\n"
     ]
    }
   ],
   "source": [
    "examples = datasets[\"train\"][:5]\n",
    "features = preprocess_function(examples)\n",
    "print(len(features[\"input_ids\"]), len(features[\"input_ids\"][0]), [len(x) for x in features[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dc11911-b731-4c65-8120-7a4ad4aa778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? [SEP] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? the tank will speed up faster than the toy car [SEP]',\n",
       " '[CLS] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? [SEP] a tank weighs around 63 tons. a toy car weighs 1. 5 kg. because of this? the toy car will speed up faster than the tank [SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "[tokenizer.decode(features[\"input_ids\"][idx][i]) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46bef0f7-7a5d-43c5-9fcb-fd4ec41cf9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_datasets = datasets.map(preprocess_function, batched=True)\n",
    "#print(encoded_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f7c4b4f-c37a-423c-b5aa-f6aa6d56f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b70edf3e-ddec-4110-9888-5dfaa6b89cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # Add back labels\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e1bd0e-18f9-4c18-8404-ec91609ac08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing stuff. Be sure to create encoded_datasets if you're running this. \n",
    "#accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "#features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "#batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "#[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02763447-68f9-448c-93fc-b2f030126e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the F1 score metric to evaluate our predictions. \n",
    "\n",
    "#Old evaluator.\n",
    "'''\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}\n",
    "'''\n",
    "\n",
    "#New evaluator.\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    \n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": f1_score(label_ids, preds, average='micro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93099c3-efa5-4dc0-832b-2dad3d393318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: The ranger and the rustler both were riding horses that galloped at the same speed.  The rustler left at 01:00 where as the ranger left at 0500 hours. Who has traveled further?? \n",
      "O1: the ranger\n",
      "O2: the rustler\n",
      "A: Option 2\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Option2', 'label', 'question', 'Option1'],\n",
      "        num_rows: 564\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Option2', 'label', 'question', 'Option1'],\n",
      "        num_rows: 81\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Option2', 'label', 'question', 'Option1'],\n",
      "        num_rows: 162\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# A cell to reset the dataset if/when problems occur with it.\n",
    "# Probably good to run this if you ran the above cells, since there's a lot of testing stuff for one model\n",
    "\n",
    "datasets = load_dataset(\"json\", data_files={'train':'Project/QQA_Data/QQA_train.json', \n",
    "                                           'validation':'Project/QQA_Data/QQA_dev.json', \n",
    "                                           'test':'Project/QQA_Data/QQA_test.json'})\n",
    "\n",
    "#Printing the dataset contents\n",
    "print('Q: ' + datasets['train'][0]['question'])\n",
    "print('O1: ' + datasets['train'][0]['Option1'])\n",
    "print('O2: ' + datasets['train'][0]['Option2'])\n",
    "print('A: ' + datasets['train'][0]['answer'])\n",
    "\n",
    "#Let's get rid of the other columns\n",
    "datasets = datasets.remove_columns(['question_char', 'question_sci_10E',\n",
    "                         'question_sci_10E_char',\n",
    "                         'question_mask', 'type',])\n",
    "\n",
    "#We now only have a question, answer, and 2 options.\n",
    "\n",
    "datasets = datasets.rename_column('answer', 'label')\n",
    "\n",
    "def set_labels(example):\n",
    "    #print(example)\n",
    "    example[\"label\"] = int(example[\"label\"][-1]) - 1\n",
    "    return example\n",
    "\n",
    "datasets = datasets.map(set_labels)\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1187dac7-b9c6-4c60-b26f-b28ba10d4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training function. Duplicate and change model name for other models.\n",
    "\n",
    "modelName = \"\"\n",
    "\n",
    "def autoTrain(model_name = 'bert-base-uncased', batch_size = 16):\n",
    "    global model\n",
    "    global tokenizer\n",
    "    global modelName\n",
    "    modelName = model_name\n",
    "    model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "    \n",
    "    encoded_datasets = datasets.map(preprocess_function, batched=True)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        f\"{model_name}-finetuned-QQA\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=encoded_datasets[\"train\"],\n",
    "        eval_dataset=encoded_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a012d073-cddd-4ae3-ab6c-aefc648d22cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Option2', 'label', 'question', 'Option1'],\n",
      "    num_rows: 162\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#Cell for testing\n",
    "print(datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a1871d6-93e8-4158-8875-093decb96888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example prediction\n",
    "\n",
    "prompt = \"I have 5 bagels and Joe has 2. Who has more bagels?\"\n",
    "candidate1 = \"Me\"\n",
    "candidate2 = \"Joe\"\n",
    "\n",
    "\n",
    "inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n",
    "labels = torch.tensor(0).unsqueeze(0)\n",
    "outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
    "logits = outputs.logits\n",
    "\n",
    "predicted_class = logits.argmax().item()\n",
    "predicted_class\n",
    "\n",
    "#Note that it will output a 0 or 1, where 0 = Option 1 and 1 = Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23131c0b-4967-462a-a357-11bf5ce60a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eval the most recently trained model\n",
    "def evaluate_hf_model():\n",
    "\n",
    "    global model\n",
    "    global tokenizer\n",
    "\n",
    "            \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Get predictions, and save corresponding reference (if we were using the whole dataset, we wouldn't need this step)\n",
    "    for ex in datasets[\"test\"]:\n",
    "\n",
    "        #Based on the above cell, get \n",
    "        prompt = ex['question']\n",
    "        candidate1 = ex['Option1']\n",
    "        candidate2 = ex['Option2']\n",
    "        \n",
    "        inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True)\n",
    "        labels = torch.tensor(0).unsqueeze(0)\n",
    "        outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        predicted_class = logits.argmax().item()\n",
    "        predicted_class\n",
    "\n",
    "\n",
    "        predictions.append(predicted_class)\n",
    "        references.append(ex['label'])\n",
    "\n",
    "    # Compute metrics\n",
    "    global modelName\n",
    "    print('Performance of {} : {}'.format(modelName, f1_score(references, predictions, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f6b934-2ac4-4ed8-9851-6190e2abc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndEval(model_name, batch_size):\n",
    "    autoTrain(model_name, batch_size)\n",
    "    #eval_hf_model evaluates whatever model we just trained because of global variables. \n",
    "    #As such we have it eval after training.\n",
    "    evaluate_hf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a7c809-1c79-404a-bf3e-27264b648617",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainAndEval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Training and evaluating bert-base-uncased\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainAndEval\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainAndEval' is not defined"
     ]
    }
   ],
   "source": [
    "#Training and evaluating bert-base-uncased\n",
    "trainAndEval(\"bert-base-uncased\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f783e4e2-54f4-4697-b34e-fe2bfbee0ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73f3decaf004f91aabc2423895f39ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda9aafbaa0b4d88bf6953973dd1841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db55b6dbecc44f1a86eb76b178c7ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe60bdebc45431da733c5b0f667aa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61e87f2eab04b45be2ad43c6483a966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e5fd438c5b48ec8b25770f842d0d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756d602f75b640988f98584c3f400721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0be4aa38b14c269905764c4d40465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 2:11:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698733</td>\n",
       "      <td>0.530864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.580247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.750790</td>\n",
       "      <td>0.567901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of cardiffnlp/twitter-roberta-base-sentiment-latest : 0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"cardiffnlp/twitter-roberta-base-sentiment-latest\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a92285ba-4939-4bdf-859d-ff9ef94b9003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52d1bcbd78c4336b9d1a0e1d2e2a483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e44cf78d91b4c019cfbfffeeb6d186d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505a4fe80b5c4faea61b99994b45a42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac51f52198f4270be588ab684c64b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e71f545e074db6b8fc2e01c09a64db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d8a040be194f068601f86093fd1b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103b87759f7a4842a6d6d7acd4bdfbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba85c289f0841bbaf9611b0896f6872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 1:04:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693211</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693783</td>\n",
       "      <td>0.432099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694439</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of distilbert/distilbert-base-uncased : 0.4876543209876543\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"distilbert/distilbert-base-uncased\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c65d8b82-b654-4fe6-ac2d-11c64af3644e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fc8ab17c024a05a52995066d818ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--dccuchile--bert-base-spanish-wwm-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc8fa48a6be457e838d049d0878e6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccd4c7c4c514234a643a9767064b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeaa52345214aaea9866add4c9697f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004d98b6efae476aad5a5bc8446d4b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/480k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f0e5e403f146bd9c829b8cc37ced59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061c3290d1ae49278ba7c7d868cc0b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4638f6f270a4566b1d88caba6d5df1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c58cc82d64315afcf15c328d62b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 3:06:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693796</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693794</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693537</td>\n",
       "      <td>0.382716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of dccuchile/bert-base-spanish-wwm-cased : 0.5493827160493827\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"dccuchile/bert-base-spanish-wwm-cased\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c4a2907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf3945ae934469ab7a2d741b3bf04c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--deepset--roberta-base-squad2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7865a0b4494b508d007869acf39efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d61aade60d461aac0f169428285793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d3be8836514eb3ac84829e33addbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f393ec28fdc422ab59c2fac7c226165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868b3d53c6f94dd9aa4b2661f21b6830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b12ce791554e288e071783fd1ad49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be148a0a4344dda93eaca8441e07640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576a79126ed740bca33b1ca6a2516d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 1:55:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694271</td>\n",
       "      <td>0.493827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.580247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692599</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of deepset/roberta-base-squad2 : 0.49382716049382713\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('deepset/roberta-base-squad2', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a955ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca697634ecf443b29bc95c58c655b2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\braph\\.cache\\huggingface\\hub\\models--Intel--dynamic_tinybert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3038a8ace74b929377d4b0b417bb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at Intel/dynamic_tinybert and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288e20a8ae274d839e59f7b0eba52069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/351 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3fa0bf96a442509da3e882ca9f813e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9938136aa2b245f1876c0494223f433a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01b95927da141cf8888f47d266fae60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b3af760564106b6c79f707985ca2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a4319f8c254e5eab5b87da633e2976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44552eff56ee41c6a71506cfc6878a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 51:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693223</td>\n",
       "      <td>0.493827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693255</td>\n",
       "      <td>0.432099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693407</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Intel/dynamic_tinybert : 0.5\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('Intel/dynamic_tinybert', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e78e72be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at distilbert/distilbert-base-cased-distilled-squad and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4c602b6cd94bf6956694e3b0440f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dc7497b6f34e7f92f3e05ac264b055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf74d4f69d34ac6a12479ad05d36b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 53:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693228</td>\n",
       "      <td>0.469136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695521</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697462</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of distilbert/distilbert-base-cased-distilled-squad : 0.47530864197530864\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('distilbert/distilbert-base-cased-distilled-squad', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5cbe83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForMultipleChoice were not initialized from the model checkpoint at FabianWillner/distilbert-base-uncased-finetuned-squad and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62004523d8b34bf68ae051722fede712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d19509e6941485e96763b4202c30dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9422cbd620d74bb2983b68db13bb99a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\braph\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 53:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693158</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693034</td>\n",
       "      <td>0.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693060</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of FabianWillner/distilbert-base-uncased-finetuned-squad : 0.4691358024691358\n"
     ]
    }
   ],
   "source": [
    "trainAndEval('FabianWillner/distilbert-base-uncased-finetuned-squad', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc96315c-17f3-428c-9c42-92b4a877c18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at siebert/sentiment-roberta-large-english and are newly initialized: ['classifier.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a6e68ebc35406889a9fe6c7de17b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/564 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8da9efa0a346258632a7534dd86e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/81 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c5cb6a5a774a029ab915b8b2e494f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/162 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/opt/anaconda3/envs/NLP/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 3:27:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693141</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693142</td>\n",
       "      <td>0.543210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of siebert/sentiment-roberta-large-english : 0.4382716049382716\n"
     ]
    }
   ],
   "source": [
    "trainAndEval(\"siebert/sentiment-roberta-large-english\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb2903-77f2-456d-a833-522aac8aea4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "809ea691-1d91-4377-b132-cfea9edd10e5",
   "metadata": {},
   "source": [
    "# Comparison:\n",
    "\n",
    "The models that we evaluated were the following:\n",
    "\n",
    "Baseline:\n",
    "\n",
    "The baseline model, bert-base-uncased, and its variants. Most are designed for masked langauge modeling with similar training data, so that the only major differences are the architecture of the transformer. Some, however, use different training data. \n",
    "\n",
    "- bert-base-uncased, trained on a large corpus of unlabeled data with the objective of masked language modeling and next sentence prediction. Because there are no \"special\" features in this version of BERT, and because of its ubiquity, it is used as a baseline for other models to be compared to in this project. https://huggingface.co/google-bert/bert-base-uncased\n",
    "- distilbert-base-uncased, trained on the same data as the regular bert-base-uncased. It is smaller and faster than regular BERT, and provides an example of how reducing the number of parameters (from 110M to 67M) affects a model's ability to preform QQA. Notably, distilbert trained faster, at 0.18 it/s instead of the regular BERT's 0.08 it/s. https://huggingface.co/distilbert/distilbert-base-uncased\n",
    "- bert-base-spanish-wwm-cased, trained on a large corpus of Spanish data. Used as an example of how training data may affect a model's ability to preform QQA. Notably, fine-tuning this model took much more time than regular BERT, with it training at a rate of 0.03 it/s. https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased\n",
    "\n",
    "SQuAD:\n",
    "\n",
    "Modeles trained in SQUAD, a labelled dataset containing questions and answers drawn from the questions. Unlike the basic BERT model, these models have been trained/fine-tuned on labelled data. \n",
    "\n",
    "- Roberta-base-squad2, a version of RoBERTA trained on labeled data (in this case, the SQUAD dataset). As labeled data contains questions and answers, and our QQA task is fundamentally question-answering, it should affect the ability of the model to preform QQA. https://huggingface.co/deepset/roberta-base-squad2\n",
    "- Dynamic-Tinybert, an even smaller version of BERT fine-tuned for the task of question answering. It will serve to show how decreasing a model's size with pretrained data can affects its QQA ability.  https://huggingface.co/Intel/dynamic_tinybert\n",
    "- distilbert-base-uncased-finetuned-squad, a distilbert variant that serves mostly as something to be compared to the cased variant and non-squad variant. When compared to the non-finetuned variant, it demonstrates how being fine-tuned on labelled data affects the same model's QQA ability. https://huggingface.co/FabianWillner/distilbert-base-uncased-finetuned-squad\n",
    "- distilbert-base-cased-distilled-squad, a cased version of distilbert fine-tuned on distilled SQUAD data. It mostly shows how being a cased model affects its preformance compared to the uncased model above. https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad\n",
    "\n",
    "Sentiment Analysis Models:\n",
    "\n",
    "Models designed for sentiment analysis. \n",
    "\n",
    "- cardiffnlp/twitter-roberta-base-sentiment-latest, a RoBERTa-base model trained on ~124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark. As this is trained for sentiment analysis, it'll provide insight into how being fine-tuned for another task beforehand affects a model's ability to preform QQA. It will also serve as the baseline for the sentiment analysis models as it contains no other notable features.\n",
    "- sentiment-roberta-large-english, a RoBERTa variant trained on a diverse source of text to preform positive/negative sentiment analysis. sentiment-roberta, unlike the previous model, is not trained on only one type of data and shows to demonstrate how more diverse data affects a model's ability to preform QQA. https://huggingface.co/siebert/sentiment-roberta-large-english \n",
    "- feel-it-italian-sentiment, a sentiment analysis model trained on foreign language data (in this case, Italian). Serves mostly as a metric on how foreign languages affect a basic sentiment analysis model's ability to preform QQA. feel-it was trained on Italian tweets that were annotated. https://huggingface.co/MilaNLProc/feel-it-italian-sentiment (In progress)\n",
    "\n",
    "\n",
    "All models were fine-tuned on the QQA dataset for 3 epochs with a batch size of 16, and evaluated using the evaluate_hf_model() function afterward. For evaluation, the scikit F1 micro score was used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3818375-0070-4401-a42a-dee04698704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the name and accuracy to avoid having to redo everything all the time.\n",
    "#Also good for graphing. \n",
    "\n",
    "#Names are shortened to be readable on the graphs.\n",
    "modelNameAcc = [\n",
    "    #Baseline, masked language\n",
    "    [\"bert\", 0.5185185185185185],\n",
    "    [\"distilbert\", 0.49382716049382713],\n",
    "    [\"bert-base-spanish\", 0.5432098765432098],\n",
    "\n",
    "    #Squad\n",
    "    ['Roberta-base-squad2', 0.49382716049382713],\n",
    "    [\"dynamic-tinybert\", 0.5], \n",
    "    ['distilbert-base-cased-distilled-squad', 0.47530864197530864],\n",
    "    ['distilbert-base-uncased-finetuned-squad', 0.4691358024691358],\n",
    "    \n",
    "    #Sentiment Analysis\n",
    "    [\"twitter-roberta\", 0.47530864197530864],\n",
    "    ['large-english', 0.4382716049382716]\n",
    "]\n",
    "\n",
    "#We're getting a LOT of models, so it may be a good idea to graph by category\n",
    "\n",
    "baselineModles = []\n",
    "\n",
    "SQuADModels = []\n",
    "\n",
    "SentimentAnalysisModles = []\n",
    "\n",
    "#Take the best accuracy of each category and compare to each other. \n",
    "TopOfEach = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21a7cafa-d78a-4bfb-8335-3727ac3f37fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot model names, accuracies, on a graph for easy comparison\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#X points for plotting\n",
    "xpoints = np.linspace(1, len(modelNameAcc), len(modelNameAcc))\n",
    "ypoints = np.zeros(len(modelNameAcc))\n",
    "\n",
    "countModels = 0\n",
    "names = []\n",
    "for k in range(len(modelNameAcc)):\n",
    "    model, acc = modelNameAcc[k]\n",
    "    countModels += 1\n",
    "    ypoints[k] = acc\n",
    "    names.append(model)\n",
    "\n",
    "#Set plot and plot\n",
    "plt.xticks(xpoints, names)\n",
    "plt.bar(xpoints, ypoints)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0711f-7fc9-4784-81c1-1537b1eccdce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
